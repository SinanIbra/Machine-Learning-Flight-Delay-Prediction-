# -*- coding: utf-8 -*-
"""Flight_Delay_A1_ML_S.I_.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1_1vw5Vuma9E6Dp_2akoVCxi1cOnrGrSX
"""

import pandas as pd
import sklearn
import numpy as np
import matplotlib.pyplot as plt
from sklearn import preprocessing
import datetime
from sklearn.ensemble import IsolationForest

import seaborn as sns

sns.set()

model= pd.read_csv("flight_delay.csv")

#to be able to call the feature throught model.NAME or df.FEATURE
model.columns = [c.replace(' ', '_') for c in model.columns]

# simple way to detect and remove outliers
ma=max(model['Delay'])
print(ma)
plt.hist(model['Delay'].values)
plt.show
model = model[model['Delay'] < 200]



#labeling airports
le = preprocessing.LabelEncoder()
model.dtypes
model["Destination_Airport"]=le.fit_transform(model["Destination_Airport"])
model["Depature_Airport"]=le.fit_transform(model["Depature_Airport"])

model.dtypes

model.info()

"""model[Scheduled_depature_time] = pd.to_datetime(model.Scheduled_depature_time, unit='s')"""

#adding new variables and deducing some important features
date_format = "%y-%m-%d %H:%M:%S"
model['Scheduled_depature_time'] = pd.to_datetime(model.Scheduled_depature_time)
model['Scheduled_arrival_time'] = pd.to_datetime(model.Scheduled_arrival_time)
model.info()


model["Scheduled_depature_hour"] = pd.to_datetime(model.Scheduled_depature_time,format=date_format).dt.hour
model["Scheduled_depature_year"] = pd.to_datetime(model.Scheduled_depature_time,format=date_format).dt.year

model["Scheduled_arrival_year"] = pd.to_datetime(model.Scheduled_arrival_time,format=date_format).dt.year
model["Scheduled_depature_month"] = pd.to_datetime(model.Scheduled_depature_time,format=date_format).dt.month
model["Scheduled_depature_dayofweek"] = pd.to_datetime(model.Scheduled_depature_time,format=date_format).dt.dayofweek
model["Scheduled_depature_weekofyear"] = pd.to_datetime(model.Scheduled_depature_time,format=date_format).dt.weekofyear


model["Scheduled_depature_minute"] = pd.to_datetime(model.Scheduled_depature_time,format="%d/%m/%Y %h/%m/%s").dt.minute  
#model["Scheduled_arrival_hour"] = pd.to_datetime(model.Scheduled_arrival_time,format="%d/%m/%Y %h/%m/%s").dt.hour

model.head()

#Scheduled_depature_hour vs Delay (in minutes), we can't tell much
model.plot(x='Scheduled_depature_hour', y='Delay', style='.')
plt.title('delay')
plt.xlabel('Scheduled_depature_hour')
plt.ylabel('Delay (minutes)')
plt.show()

#claculating the Duration of filghts
Scheduled_depature_time=list(model.Scheduled_depature_time)
Scheduled_arrival_time=list(model.Scheduled_arrival_time)
Duration=[]
for i in range(len(Scheduled_depature_time)):
    a=Scheduled_depature_time[i]
    b=Scheduled_arrival_time[i]
    Duration.append(pd.Timedelta(b - a))

model['Duration']= Duration

model.head(7)

#splitting the dataset by the year
model_train = model[model['Scheduled_depature_year'] <= 2017]
model_test = model[model['Scheduled_depature_year'] > 2017 ]
#splitting the dataset in the year for one month only
model_month= model[( model['Scheduled_depature_month'] == 11 ) & (model['Scheduled_depature_year'] == 2015)]



#experimenting with model_month dataframe
format_duration=""
model_month.shape

model_month['Duration_mins']=(pd.to_datetime(model.Duration,format=format_duration).dt.hour)*60 + (pd.to_datetime(model.Duration,format=format_duration).dt.minute)  
model_train['Duration_mins']=(pd.to_datetime(model_train.Duration,format=format_duration).dt.hour)*60 + (pd.to_datetime(model_train.Duration,format=format_duration).dt.minute)
model_test['Duration_mins']=(pd.to_datetime(model_test.Duration,format=format_duration).dt.hour)*60 + (pd.to_datetime(model_test.Duration,format=format_duration).dt.minute)

#plotting 
model_month.plot(x='Duration_mins', y='Delay', style='.')
plt.title('delay')
plt.xlabel('Duration')
plt.ylabel('Delay (minutes)')
plt.show()
#model_train.head()
#model_test.head()

'''testing what feature has the most affect on the Target (delay)'''
from sklearn.ensemble import ExtraTreesRegressor
X = model_train.loc[:, ['Duration_mins','Scheduled_depature_dayofweek','Scheduled_depature_hour','Depature_Airport','Scheduled_depature_weekofyear']]
X.head()

y=model_train.loc[:,'Delay']


selection = ExtraTreesRegressor()
selection.fit(X, y)

plt.figure(figsize = (12,8))
feat_importances = pd.Series(selection.feature_importances_, index=X.columns)
feat_importances.nlargest(20).plot(kind='barh')
plt.show()

sns.catplot(y = "Delay", x = "Duration_mins", data = model_train.sort_values("Delay", ascending = False), kind="boxen", height = 6, aspect = 3)
plt.show()

from sklearn.ensemble import RandomForestRegressor
reg_rf = RandomForestRegressor()
reg_rf.fit(X, y)

X_test = model_test.loc[:, ['Duration_mins','Scheduled_depature_dayofweek','Scheduled_depature_hour','Depature_Airport','Scheduled_depature_weekofyear']]
X.head()

y_test=model_test.loc[:,'Delay']

y_pred = reg_rf.predict(X_test) - 27
for i in range(len(y_pred)):
    if y_pred[i] < 0 :
        y_pred[i] = 0

reg_rf.score(X, y_train)



reg_rf.score(X_test, y_test)

sns.distplot(y_test-y_pred)
plt.show()

plt.scatter(y_test, y_pred, alpha=1)
plt.xlabel("y_Test")
plt.ylabel("y_pred")
plt.show()

#errors calculation
from sklearn import metrics
print('MAE:', metrics.mean_absolute_error(y_test, y_pred))
print('MSE:', metrics.mean_squared_error(y_test, y_pred))
print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))

from sklearn.pipeline import Pipeline
from sklearn.preprocessing import PolynomialFeatures 
from sklearn import linear_model

#Data preparing for polynomial regression
poly = PolynomialFeatures(degree=2)

df_train=pd.DataFrame()
df_test=pd.DataFrame()
y_train=pd.DataFrame()
y_test=pd.DataFrame()

df_train['Duration_mins'] = model_train['Duration_mins']
df_test['Duration_mins']= model_test['Duration_mins']
y_train = model_train.Delay.values
y_test = model_test.Delay.values

from sklearn.model_selection import cross_val_score

# polynomial regression
x_train_poly = poly.fit_transform(df_train)
x_test_poly = poly.fit_transform(df_test)

lin = linear_model.LinearRegression()
lin=lin.fit(x_train_poly, y_train)

co=lin.coef_
intercept = lin.intercept_

'''here with polynomyal regression we can say that x^2 is a new variable called z for example, so we treat it that way'''
x_axis= np.arange(0,800,1)
res= intercept+co[1]*x_axis+co[2]*x_axis*x_axis
plt.scatter(df_test,y_test)
plt.plot(x_axis,res,color='r')
plt.show

from sklearn.metrics import r2_score
prediction = lin.predict(x_test_poly)
r2_score(prediction, y_test)

'''Regulization using lasso '''
from sklearn.linear_model import Lasso, Ridge
from sklearn import metrics
from sklearn.metrics import mean_squared_error
from sklearn.linear_model import Lasso, Ridge

l = Lasso()
r = Ridge()
l.fit(df_train, y_train)
r.fit(df_train, y_train)

print("Lasso Coefficient", l.coef_)
print("Ridge Coefficient", r.coef_)
alphas = [1,1.5,2,2.5]
losses = []
for alpha in alphas:
    l = Lasso(alpha=alpha)
    l.fit(df_train, y_train)
    l.coef_
    y_pred_L = l.predict(df_test)
    mse = mean_squared_error(y_test, y_pred)
    losses.append(mse)
best_a = alphas[np.argmin(losses)]
print("Best alpha:", best_a)

plt.plot(alphas, losses)
plt.title("Lasso alpha value selection")
plt.xlabel("alpha")
plt.ylabel("Mean squared error")
plt.show()

l = Lasso(best_a)
l.fit(df_train, y_train)
x_test= df_test.values
x_test = x_test.reshape(-1,1)
y_pred_L = l.predict(df_test)
print('MAE:', metrics.mean_absolute_error(y_test, y_pred_L))
print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, y_pred_L)))
print('Coefficient of Determination:', metrics.r2_score(y_test, y_pred_L))

y_pred_L



























